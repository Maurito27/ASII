"""
Cerebro V7.0 - M√°quina de Estados Enterprise
--------------------------------------------
Orquesta la interacci√≥n con el usuario mediante estados definidos:
1. PERFILADO: Identifica el rol del usuario.
2. DIAGN√ìSTICO: Analiza la consulta sin buscar respuesta final.
3. SELECCI√ìN: Consulta al Bibliotecario (RAG Fase 1).
4. LECTURA: Consulta al Lector (RAG Fase 2).
"""
import os
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_community.chat_message_histories import SQLChatMessageHistory

# Importaciones V7
from app.core.config import Configuracion
from app.core.contracts import SCORE_THRESHOLD
from app.logic.rag_engine_v7 import buscar_manual_candidato, buscar_contenido_profundo
from app.logic.session_manager import gestor_sesiones

# Configuraci√≥n del LLM
llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-exp", 
    temperature=0.0,
    google_api_key=Configuracion.GOOGLE_API_KEY
)

# --- PROMPTS DIN√ÅMICOS POR PERFIL ---
SYSTEM_PROMPTS = {
    "SISTEMAS": """
    Eres un Arquitecto de Software Senior experto en Softland ERP.
    Tu usuario es t√©cnico (Sistemas/IT).
    - Ve al grano. No uses saludos largos.
    - Si hay tablas o nombres de campos t√©cnicos, √∫salos tal cual (SQL).
    - Asume que el usuario sabe navegar en Windows.
    - Prioriza la precisi√≥n t√©cnica sobre la pedagog√≠a.
    """,
    "ADMIN": """
    Eres un Consultor Funcional Senior de Softland ERP.
    Tu usuario es administrativo (Ventas/RRHH/Contabilidad).
    - Explica paso a paso con paciencia.
    - Usa analog√≠as si es necesario.
    - Avisa siempre si una acci√≥n es irreversible.
    - Tono: Profesional, emp√°tico y claro.
    """
}

def obtener_historial(session_id: str):
    try:
        history = SQLChatMessageHistory(
            session_id=session_id, 
            connection_string=Configuracion.RUTA_HISTORIAL_CHAT
        )
        return history, "\n".join([f"{m.type.upper()}: {m.content}" for m in history.messages[-4:]])
    except: 
        return None, ""

# --- FASE 1: DIAGN√ìSTICO & SELECCI√ìN ---

async def fase_bibliotecario(pregunta, session_id, perfil):
    """
    Consulta la biblioteca para identificar el manual correcto.
    """
    print(f">> [Brain V7] Fase Bibliotecario: Buscando manual para '{pregunta}'")
    
    candidatos = buscar_manual_candidato(pregunta)
    
    if not candidatos:
        return (
            "‚ùå No encontr√© ning√∫n manual vigente que coincida con tu consulta.\n"
            "Por favor, intenta con el nombre del m√≥dulo (ej: 'Ventas', 'Sueldos').",
            "ESPERANDO_INPUT", 
            None
        )

    mejor_candidato = candidatos[0]
    score = mejor_candidato["score"]
    
    # Reglas de Oro
    if score < SCORE_THRESHOLD["AUTO_SELECT"]:
        print(f"   ‚úÖ Auto-selecci√≥n: {mejor_candidato['nombre_archivo']} (Score: {score:.3f})")
        return (None, "LECTURA_PROFUNDA", mejor_candidato)
        
    elif score < SCORE_THRESHOLD["CONFIRM"]:
        msg = (
            f"üîé Encontr√© este manual relacionado: **{mejor_candidato['nombre_archivo']}**\n"
            f"_(Versi√≥n {mejor_candidato['version']} - A√±o {mejor_candidato['anio']})_\n\n"
            "¬øEs este el manual correcto?"
        )
        gestor_sesiones.actualizar_metadata(session_id, {"candidato_pendiente": mejor_candidato})
        return (msg, "ESPERANDO_CONFIRMACION", None)
        
    else:
        opciones = "\n".join([f"- {c['nombre_archivo']}" for c in candidatos[:3]])
        msg = (
            "ü§î Encontr√© opciones lejanas:\n"
            f"{opciones}\n\n"
            "Por favor, s√© m√°s espec√≠fico."
        )
        return (msg, "ESPERANDO_INPUT", None)

# --- FASE 2: LECTURA & RESPUESTA ---

async def fase_lector(pregunta, manual_meta, perfil, historial_txt):
    """
    Lee el contenido dentro del manual seleccionado y genera la respuesta.
    """
    nombre_doc = manual_meta.get("nombre_archivo", "Desconocido")
    doc_id = manual_meta.get("doc_id")
    version_doc = manual_meta.get("version", "N/A")
    
    if not doc_id:
        print(f"‚ùå ERROR CR√çTICO: Metadata corrupta, falta doc_id: {manual_meta}")
        return ("‚ö†Ô∏è Error interno: El √≠ndice del manual est√° da√±ado. Recomienda al admin ejecutar `ingest_v7.py`.", [])

    print(f">> [Brain V7] Fase Lector: Leyendo ID {doc_id[:8]}... ({nombre_doc})")
    
    # 1. B√∫squeda Profunda
    evidencias = buscar_contenido_profundo(pregunta, doc_id)
    
    if not evidencias:
        return (
            f"üìÇ Abr√≠ el manual **{nombre_doc}**, pero no encontr√© referencias exactas a '{pregunta}'.\n"
            "Intenta reformular la pregunta con t√©rminos m√°s espec√≠ficos.",
            []
        )

    # 2. Construcci√≥n del Contexto
    contexto_str = ""
    for i, ev in enumerate(evidencias):
        contexto_str += f"--- FRAGMENTO {i+1} (P√°g {ev['pagina']} - {ev['seccion']}) ---\n{ev['texto']}\n\n"

    # 3. System Prompt seg√∫n perfil
    system_prompt = SYSTEM_PROMPTS.get(perfil, SYSTEM_PROMPTS["ADMIN"])
    
    # 4. Prompt de Usuario con Instrucciones de Formato
    prompt_usuario = f"""
CONTEXTO (Manual: {nombre_doc}, v{version_doc}):
{contexto_str}

HISTORIAL:
{historial_txt}

PREGUNTA:
"{pregunta}"

INSTRUCCIONES DE FORMATO PARA TELEGRAM:
1. **Contenido:** Responde SOLO con info del contexto. Si falta algo, di "No est√° documentado en este manual".

2. **Jerarqu√≠a Visual:**
   - Usa emojis para t√≠tulos principales (üìå ‚öôÔ∏è üìã ‚ö†Ô∏è)
   - Usa negrita limpia para subt√≠tulos: **T√≠tulo**
   
3. **C√≥digos T√©cnicos:**
   - TODO nombre de tabla, campo, objeto debe ir en monoespaciado: `GRTQVH`, `FCRMVH`
   - Ejemplos SQL en bloques de c√≥digo

4. **Listas:**
   - Usa vi√±etas Unicode: ‚Ä¢ (bullet)
   - NO uses asteriscos (*)
   - Formato: ‚Ä¢ **Concepto:** Explicaci√≥n

5. **Citas de Fuente:**
   - NO repitas (p√°g. X) en cada oraci√≥n
   - Agr√∫palas al final de cada secci√≥n importante: _(Ref: P√°gs 3, 5, 7)_

6. **Espaciado:**
   - Separa secciones con l√≠nea en blanco
   
7. **Rutas de navegaci√≥n:**
   - Formato: _Men√∫_ ‚Üí _Submenu_ ‚Üí _Opci√≥n_

IMPORTANTE: El formato debe ser limpio y escaneable visualmente.
"""
    
    # 5. Invocaci√≥n del LLM
    mensajes = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=prompt_usuario)
    ]
    
    respuesta_llm = await llm.ainvoke(mensajes)
    
    # 6. Footer con trazabilidad
    footer = f"\n\n_Fuente: {nombre_doc} (v{version_doc})_"
    
    return (respuesta_llm.content + footer, [manual_meta])

# --- CONTROLADOR PRINCIPAL (M√ÅQUINA DE ESTADOS) ---

async def generar_respuesta_inteligente(pregunta: str, session_id: str = "default") -> dict:
    """
    Orquestador principal del cerebro conversacional.
    """
    # 1. Recuperar Sesi√≥n
    sesion = gestor_sesiones.obtener_sesion(session_id)
    estado_actual = sesion.get("estado", "INICIO")
    perfil = sesion.get("perfil", "ADMIN")
    
    # Comandos r√°pidos
    if pregunta.startswith("/perfil"):
        nuevo = "SISTEMAS" if "sistemas" in pregunta.lower() else "ADMIN"
        gestor_sesiones.actualizar_sesion(session_id, perfil=nuevo)
        return {"texto": f"‚úÖ Perfil actualizado a: **{nuevo}**", "archivos": []}
        
    if pregunta.lower() in ["salir", "cancelar", "reset", "/limpiar", "/start"]:
        gestor_sesiones.limpiar_sesion(session_id)
        return {"texto": "üßπ Memoria limpiada. ¬øEn qu√© puedo ayudarte?", "archivos": []}

    # --- M√ÅQUINA DE ESTADOS ---
    
    # CASO A: Esperando confirmaci√≥n de manual
    if estado_actual == "ESPERANDO_CONFIRMACION":
        if any(x in pregunta.lower() for x in ["si", "s√≠", "claro", "es ese", "correcto", "ok"]):
            candidato = sesion["metadata"]["candidato_pendiente"]
            gestor_sesiones.cambiar_estado(
                session_id, 
                "LECTURA_PROFUNDA", 
                doc=candidato["nombre_archivo"], 
                meta=candidato
            )
            return {
                "texto": f"üëç Perfecto. Abriendo **{candidato['nombre_archivo']}**. ¬øQu√© necesitas saber?", 
                "archivos": []
            }
        else:
            # Usuario rechaz√≥
            gestor_sesiones.limpiar_sesion(session_id)
            return {
                "texto": "Entendido, descartamos ese manual. ¬øQu√© tema espec√≠fico buscamos?", 
                "archivos": []
            }

    # CASO B: Ya estamos dentro de un manual (Modo Profundo)
    if estado_actual == "LECTURA_PROFUNDA":
        hist_obj, hist_txt = obtener_historial(session_id)
        manual = sesion["metadata"]
        
        resp_txt, archs = await fase_lector(pregunta, manual, perfil, hist_txt)
        
        if hist_obj:
            hist_obj.add_user_message(pregunta)
            hist_obj.add_ai_message(resp_txt)
            
        return {"texto": resp_txt, "archivos": [manual.get("nombre_archivo")]}

    # CASO C: B√∫squeda Nueva (Modo Bibliotecario)
    msg_biblio, nuevo_estado, meta_manual = await fase_bibliotecario(pregunta, session_id, perfil)
    
    if nuevo_estado == "LECTURA_PROFUNDA":
        # Auto-selecci√≥n exitosa -> Leemos inmediatamente
        gestor_sesiones.cambiar_estado(
            session_id, 
            "LECTURA_PROFUNDA", 
            doc=meta_manual["nombre_archivo"], 
            meta=meta_manual
        )
        
        hist_obj, hist_txt = obtener_historial(session_id)
        resp_txt, archs = await fase_lector(pregunta, meta_manual, perfil, hist_txt)
        
        if hist_obj:
            hist_obj.add_user_message(pregunta)
            hist_obj.add_ai_message(resp_txt)
            
        return {"texto": resp_txt, "archivos": [meta_manual.get("nombre_archivo")]}
        
    elif nuevo_estado == "ESPERANDO_CONFIRMACION":
        gestor_sesiones.cambiar_estado(session_id, "ESPERANDO_CONFIRMACION")
        return {"texto": msg_biblio, "archivos": []}
        
    else:
        # Fallo o ambig√ºedad
        return {"texto": msg_biblio, "archivos": []}